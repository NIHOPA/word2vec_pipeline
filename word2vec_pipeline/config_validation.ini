target_columns = string_list
_PARALLEL = boolean


[import_data]

    input_data_directories = string_list
    output_data_directory = string(default="data_sql")

    data_type = string(default="csv")
    output_table = string(default="original")

[phrase_identification]

    f_abbreviations = string(default="abbreviations.csv")
    output_data_directory = string(default="data_document_scores")
    output_table = string(default="abbreviations")

[parse]

    output_table = string(default="parsed")
    output_data_directory = string(default="data_parsed")

    pipeline = string_list

    [[replace_phrases]]
	prefix = "MeSH_"

    [[pos_tokenizer]]
        POS_blacklist = string_list

[embedding]

    input_data_directory = string(default="data_parsed")
    output_data_directory = string(default="data_embeddings")
    embedding_commands = string_list

    [[w2v_embedding]]
        f_db = string(default="w2v.gensim")
      	skip_gram = integer(default=0)
      	hierarchical_softmax = integer(default=0)
        epoch_n = integer(default=80)
        window = integer(default=5)
        negative = integer(default=5)
        sample = float(default=1e-5)
        size = integer(default=300)
        min_count = integer(default=10)

    [[d2v_embedding]]
        f_db = string(default="d2v.gensim")
        epoch_n = integer(default=80)
        window = integer(default=5)
        negative = integer(default=5)
        sample = float(default=1e-5)
        size = integer(default=300)
        min_count = integer(default=10)

[score]

    output_data_directory = string(default="data_document_scores")
    mapreduce_commands = string_list
    globaldata_commands = string_list

    compute_reduced_representation = boolean

    [[reduced_representation]]
        n_components = integer(25)
	rescored_command = string
	bais_strength = float(default=1.0)

    [[term_frequency]]
        f_db = string(default="TF.csv")
    [[term_document_frequency]]
        f_db = string(default="TDF.csv")

    [[document_log_probability]]
      	f_partition_function = string(default="w2v_partition_function.h5")
      	f_db = string(default="log_prob.h5")
      	intra_document_cutoff = float(default=0.10)

    [[score_Z_weighted]]
      	kT = float(default=1.5)
      	threshold = float(default=0.0)

    [[score_simple]]
    [[score_unique]]
    [[score_simple_TF]]
    [[score_unique_TF]]
    [[score_locality_hash]]
        locality_n_bits = integer(default=12)
        locality_alpha = float(default=0.00)

    [[document_scores]]
        f_db = string(default="document_scores.h5"

[predict]
    categorical_columns=string_list

    n_estimators=integer(default=200)
    cross_validation_folds=integer(default=12)

    meta_methods=string_list

    use_SMOTE=boolean(default=False)
    use_reduced=boolean(default=False)
    use_meta=boolean(default=False)


[metacluster]

    score_method=string

    subcluster_m=integer(default=1000)
    subcluster_kn=integer(default=15)

    subcluster_pcut=float(default=0.80)
    subcluster_repeats=integer(default=1)

    output_data_directory=string(default="data_clustering")
    f_centroids=string(default="meta_cluster_centroids.h5")


[cluster]

    predict_target_directory=string(default="data_sql/")
    score_method=string

    output_data_directory=string(default="data_clustering")
    f_cluster=string(default="clustering.h5")

    clustering_commands=string_list

    [[spectral_clustering]]
        n_clusters=integer(default=4)

    [[hdbscan_clustering]]
        min_cluster_size=integer(default=30)

[postprocessing]

    compute_dispersion = boolean(default=True)
    output_data_directory=string(default="results")
    master_columns=string_list
